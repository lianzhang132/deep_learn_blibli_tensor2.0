{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "ITER0,Testing accuracy0.9166\n",
      "ITER0,training accuracy0.9100182\n",
      "ITER1,Testing accuracy0.9291\n",
      "ITER1,training accuracy0.9268364\n",
      "ITER2,Testing accuracy0.9355\n",
      "ITER2,training accuracy0.93456364\n",
      "ITER3,Testing accuracy0.9408\n",
      "ITER3,training accuracy0.94052726\n",
      "ITER4,Testing accuracy0.9429\n",
      "ITER4,training accuracy0.9441091\n",
      "ITER5,Testing accuracy0.9465\n",
      "ITER5,training accuracy0.9489091\n",
      "ITER6,Testing accuracy0.9465\n",
      "ITER6,training accuracy0.9508\n",
      "ITER7,Testing accuracy0.9517\n",
      "ITER7,training accuracy0.95469093\n",
      "ITER8,Testing accuracy0.9516\n",
      "ITER8,training accuracy0.9544909\n",
      "ITER9,Testing accuracy0.9547\n",
      "ITER9,training accuracy0.95878184\n",
      "ITER10,Testing accuracy0.9558\n",
      "ITER10,training accuracy0.9595818\n",
      "ITER11,Testing accuracy0.9573\n",
      "ITER11,training accuracy0.9616182\n",
      "ITER12,Testing accuracy0.9595\n",
      "ITER12,training accuracy0.96314543\n",
      "ITER13,Testing accuracy0.9594\n",
      "ITER13,training accuracy0.9639818\n",
      "ITER14,Testing accuracy0.9606\n",
      "ITER14,training accuracy0.96458185\n",
      "ITER15,Testing accuracy0.9623\n",
      "ITER15,training accuracy0.9666182\n",
      "ITER16,Testing accuracy0.9636\n",
      "ITER16,training accuracy0.96778184\n",
      "ITER17,Testing accuracy0.9646\n",
      "ITER17,training accuracy0.9689091\n",
      "ITER18,Testing accuracy0.9641\n",
      "ITER18,training accuracy0.9694727\n",
      "ITER19,Testing accuracy0.9665\n",
      "ITER19,training accuracy0.9705455\n",
      "ITER20,Testing accuracy0.9658\n",
      "ITER20,training accuracy0.97156364\n",
      "ITER21,Testing accuracy0.9669\n",
      "ITER21,training accuracy0.9728182\n",
      "ITER22,Testing accuracy0.9683\n",
      "ITER22,training accuracy0.97276366\n",
      "ITER23,Testing accuracy0.9676\n",
      "ITER23,training accuracy0.9737091\n",
      "ITER24,Testing accuracy0.9687\n",
      "ITER24,training accuracy0.97443634\n",
      "ITER25,Testing accuracy0.9687\n",
      "ITER25,training accuracy0.97492725\n",
      "ITER26,Testing accuracy0.9685\n",
      "ITER26,training accuracy0.9760727\n",
      "ITER27,Testing accuracy0.9692\n",
      "ITER27,training accuracy0.9764909\n",
      "ITER28,Testing accuracy0.9695\n",
      "ITER28,training accuracy0.9764182\n",
      "ITER29,Testing accuracy0.9708\n",
      "ITER29,training accuracy0.9773273\n",
      "ITER30,Testing accuracy0.9702\n",
      "ITER30,training accuracy0.9774182\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "#计算每个批次的大小\n",
    "batch_size = 100\n",
    "#计算总共的批次\n",
    "n_batch = mnist.train.num_examples//batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单地神经网络\n",
    "#tf.truncated_normal 截断的正态分布  2000位置代表神经元数量 784 代表批次数 \n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "#第二个神经元\n",
    "# W_1 = tf.Variable(tf.zeros([10]))\n",
    "# b_1 = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(prediction_0,W_1)+b_1)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#对数释然函数 交叉熵\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "#argmax 返回一维向量中最大的值所在位置\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,\n",
    "                     feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        test_acc = sess.run(accuracy,\n",
    "                       feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,\n",
    "                       feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"ITER\"+str(epoch)+\",Testing accuracy\"+str(test_acc))\n",
    "        print(\"ITER\"+str(epoch)+\",training accuracy\"+str(train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proch 1.0 不丢\n",
    "ITER30,Testing accuracy0.9723\n",
    "ITER30,training accuracy0.9958182\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
